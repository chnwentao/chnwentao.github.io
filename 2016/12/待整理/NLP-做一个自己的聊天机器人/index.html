<!DOCTYPE html><html lang=""><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>一步一步做一个自己的聊天机器人——— Word2Vec建模 | CS Learning of CHNwentao</title><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css?version=1.3"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?js?c4c99183a6a02c53d4760ae1995c3b38";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var GLOBAL = { 
  root: '/',
  algolia: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  localSearch: {"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}"},"path":"search.xml"}
} </script><link rel="icon" href="/favicon.ico"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#语料库准备获取"><span class="toc-number">1.</span> <span class="toc-text">语料库准备获取</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#维基百科简体中文语料的获取"><span class="toc-number">1.1.</span> <span class="toc-text">维基百科简体中文语料的获取</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#下载中文的-Wiki-Dump"><span class="toc-number">1.1.1.</span> <span class="toc-text">下载中文的 Wiki Dump</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#文本处理"><span class="toc-number">1.1.2.</span> <span class="toc-text">文本处理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#分词"><span class="toc-number">2.</span> <span class="toc-text">分词</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Word2Vec建模"><span class="toc-number">3.</span> <span class="toc-text">Word2Vec建模</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#模型的效果："><span class="toc-number">4.</span> <span class="toc-text">模型的效果：</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="http://7xiuu0.com1.z0.glb.clouddn.com/17-11-23/22222257.jpg"></div><div class="author-info__name text-center">Wente Guo</div><div class="author-info__description text-center">一个学习的博客网站，专注于计算机科学、机器学习、数据挖掘等的 技术分享、相关咨询及经验总结</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">134</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">184</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">19</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container" style="background-image: url(true);"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">CS Learning of CHNwentao</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span></div><div id="post-info"><div id="post-title">一步一步做一个自己的聊天机器人——— Word2Vec建模</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2016-12-15</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"> </i><a class="post-meta__categories" href="/categories/NLP/">NLP</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">1,362</span><span class="post-meta__separator">|</span><span>Reading time: 6 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div id="post-content"><p>不断更新 ing; <a id="more"></a></p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><h2 id="语料库准备获取"><a href="#语料库准备获取" class="headerlink" title="语料库准备获取"></a>语料库准备获取</h2><p>当代自然语言处理都是基于统计的，统计自然需要很多样本，因此语料和词汇资源是必不可少的。</p>
<h3 id="维基百科简体中文语料的获取"><a href="#维基百科简体中文语料的获取" class="headerlink" title="维基百科简体中文语料的获取"></a>维基百科简体中文语料的获取</h3><p>使用维基百科做训练语料有很多好处：</p>
<p>维基百科资源获取非常方便，有 Wiki Dump 可以直接下载，所有的最新备份都在里面。相比之下，其他很多语料都需要用爬虫抓取，或者付费获得。</p>
<p>维基百科的文档解析有非常多的成熟工具，直接使用开源工具即可完成正文的提取。</p>
<p>维基百科的质量较高，而且领域广泛（比较适合我要做的问题）。</p>
<p>缺点也有：</p>
<p>最主要的就是数量较少，相比国内的百度百科、互动百科等，数据量要少一个数量级。(处理后 909M )</p>
<h4 id="下载中文的-Wiki-Dump"><a href="#下载中文的-Wiki-Dump" class="headerlink" title="下载中文的 Wiki Dump"></a>下载中文的 Wiki Dump</h4><p>链接是：<a href="http://download.wikipedia.com/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2" target="_blank" rel="noopener">http://download.wikipedia.com/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2</a></p>
<p>这个压缩包里面存的是标题、正文部分，如果需要其他数据，如页面跳转、历史编辑记录等，可以到目录下找别的下载链接。</p>
<h4 id="文本处理"><a href="#文本处理" class="headerlink" title="文本处理"></a>文本处理</h4><p>首先将xml的wiki数据转换为text格式，通过下面这个脚本(process_wiki.py)实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> WikiCorpus</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    program = os.path.basename(sys.argv[<span class="number">0</span>])</span><br><span class="line">    logger = logging.getLogger(program)</span><br><span class="line"></span><br><span class="line">    logging.basicConfig(format=<span class="string">'%(asctime)s: %(levelname)s: %(message)s'</span>)</span><br><span class="line">    logging.root.setLevel(level=logging.INFO)</span><br><span class="line">    logger.info(<span class="string">"running %s"</span> % <span class="string">' '</span>.join(sys.argv))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># check and process input arguments</span></span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">3</span>:</span><br><span class="line">        <span class="keyword">print</span> globals()[<span class="string">'__doc__'</span>] % locals()</span><br><span class="line">        sys.exit(<span class="number">1</span>)</span><br><span class="line">    inp, outp = sys.argv[<span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">    space = <span class="string">" "</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    output = open(outp, <span class="string">'w'</span>)</span><br><span class="line">    wiki = WikiCorpus(inp, lemmatize=<span class="keyword">False</span>, dictionary=&#123;&#125;)</span><br><span class="line">    <span class="keyword">for</span> text <span class="keyword">in</span> wiki.get_texts():</span><br><span class="line">        output.write(space.join(text) + <span class="string">"\n"</span>)</span><br><span class="line">        i = i + <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> (i % <span class="number">10000</span> == <span class="number">0</span>):</span><br><span class="line">            logger.info(<span class="string">"Saved "</span> + str(i) + <span class="string">" articles"</span>)</span><br><span class="line"></span><br><span class="line">    output.close()</span><br><span class="line">    logger.info(<span class="string">"Finished Saved "</span> + str(i) + <span class="string">" articles"</span>)</span><br></pre></td></tr></table></figure>
<p>首先用 process_wiki.py处理这个XML压缩文件(大约20min rmbp)，执行：<code>python process_wiki.py zhwiki-latest-pages-articles.xml.bz2 wiki.zh.text</code></p>
<p>得到了大约23万多篇中文语料的text格式的语料:wiki.zh.text，大概750多M。不过查看之后发现，除了加杂一些英文词汇外，还有很多繁体字混迹其中，这里还是参考了 @licstar 《维基百科简体中文语料的获取》中的方法，安装opencc，然后将wiki.zh.text中的繁体字转化位简体字：</p>
<p><code>opencc -i wiki.zh.text -o wiki.zh.text.jian -c t2s.json</code></p>
<h2 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h2><p>这个软件很多:</p>
<ul>
<li><p>比较说免费且常用的<a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener">“结巴”中文分词</a></p>
</li>
<li><p>想自己动手做一个的话可以参考<a href="http://www.52nlp.cn/%E7%94%A8mecab%E6%89%93%E9%80%A0%E4%B8%80%E5%A5%97%E5%AE%9E%E7%94%A8%E7%9A%84%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E7%B3%BB%E7%BB%9F" target="_blank" rel="noopener">用MeCab打造一套实用的中文分词系统(我爱自然语言处理)</a></p>
</li>
<li><p>我用的是百度 内部的 NLPC (不要羡慕，嘿嘿)</p>
</li>
</ul>
<p>下面是我写的 jiaba 脚本：（用时 15 min）</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="comment"># encoding=utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    program = os.path.basename(sys.argv[<span class="number">0</span>])</span><br><span class="line">    logger = logging.getLogger(program)</span><br><span class="line"></span><br><span class="line">    logging.basicConfig(format=<span class="string">'%(asctime)s: %(levelname)s: %(message)s'</span>)</span><br><span class="line">    logging.root.setLevel(level=logging.INFO)</span><br><span class="line">    logger.info(<span class="string">"running %s"</span> % <span class="string">' '</span>.join(sys.argv))</span><br><span class="line"></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        line = line.strip().decode(<span class="string">'utf-8'</span>, <span class="string">'ignore'</span>)</span><br><span class="line">        seg_list = jieba.cut(line, cut_all=<span class="keyword">True</span>)</span><br><span class="line">        <span class="keyword">print</span> <span class="string">" "</span>.join(seg_list).encode(<span class="string">'utf-8'</span>, <span class="string">'ignore'</span>)  <span class="comment"># 全模式</span></span><br><span class="line">        i = i + <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> (i % <span class="number">10000</span> == <span class="number">0</span>):</span><br><span class="line">            logger.info(<span class="string">"Saved "</span> + str(i) + <span class="string">" articles"</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>执行如下：<br><code>cat wiki.zh.text.jian | ~/anaconda/bin/python jieba_seg.py &gt; wiki.zh.text.jian.jieba</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 剔除其他语言字符(可选)</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'./wiki.zh.text.jian.seg'</span> , <span class="string">'r'</span>) <span class="keyword">as</span> fr, open(<span class="string">'./wiki.zh.text.jian.seg.utf8'</span>, <span class="string">'a'</span>) <span class="keyword">as</span> fw:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr:</span><br><span class="line">        line = line.strip().decode(<span class="string">'utf-8'</span>, <span class="string">"gb18030"</span>).encode(<span class="string">'utf-8'</span>)</span><br><span class="line">        p = re.compile(<span class="string">ur'([\u4E00-\u9FA5a-zA-Z0-9+_]+)'</span>)</span><br><span class="line">        res = p.findall(line)</span><br><span class="line"></span><br><span class="line">        fw.write(line)</span><br><span class="line">        fw.write(<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Word2Vec建模"><a href="#Word2Vec建模" class="headerlink" title="Word2Vec建模"></a>Word2Vec建模</h2><p>我们使用 gensim中的python word2vec版本，训练word2vec模型（比原版的快），脚本train_word2vec_model.py如下：</p>
<p>参数的说明如下：</p>
<ul>
<li>size：向量的维度 * 大的size值会要求更多的训练数据，但能带来更准确的模型</li>
<li>window：在一个句子内，目标词与预测词之间的最大距离</li>
<li>min_count：忽略所有总词频低于这个值的词。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> gensim</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</span><br><span class="line"><span class="keyword">from</span> gensim.models.word2vec <span class="keyword">import</span> LineSentence</span><br><span class="line"><span class="comment">## 加载语料库</span></span><br><span class="line">sent = LineSentence(<span class="string">'./wiki.zh.text.jian.seg.utf8'</span>)</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model = Word2Vec(sent, size=<span class="number">400</span>, window=<span class="number">5</span>, min_count=<span class="number">5</span>,workers=multiprocessing.cpu_count())</span><br><span class="line"><span class="comment">## 模型保存</span></span><br><span class="line">model.save(<span class="string">'./wiki.zh.text.model'</span>)</span><br><span class="line">model.save_word2vec_format(<span class="string">'./wiki.zh.text.vector'</span>, binary=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<h2 id="模型的效果："><a href="#模型的效果：" class="headerlink" title="模型的效果："></a>模型的效果：</h2><p>让我们看一下训练好的中文维基百科word2vec模型“wiki.zh.text.vector”的效果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 加载模型</span></span><br><span class="line">model = gensim.models.Word2Vec.load(<span class="string">"./wiki.zh.text.model"</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> model.most_similar(<span class="string">u"计算机"</span>):</span><br><span class="line">    <span class="keyword">print</span> e[<span class="number">0</span>], e[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<pre><code>电脑 0.661385774612
集成电路 0.642173707485
计算器 0.637504577637
嵌入式系统 0.635099411011
软件工程 0.617608428001
图像处理 0.612333893776
信号处理 0.609744787216
模式识别 0.605699121952
计算机科学 0.605493366718
计算机图形学 0.603613495827
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.similarity(<span class="string">u"计算机"</span>, <span class="string">u"自动化"</span>)</span><br></pre></td></tr></table></figure>
<pre><code>0.56565640705507891
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> model.doesnt_match(<span class="string">u"早餐 晚餐 午餐 中心"</span>.split())</span><br></pre></td></tr></table></figure>
<pre><code>中心
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> model.most_similar(<span class="string">u"自动化"</span>):</span><br><span class="line">    <span class="keyword">print</span> e[<span class="number">0</span>], e[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<pre><code>系统工程 0.703799128532
自动控制 0.67300671339
电气工程 0.657055139542
信息系统 0.655942738056
电力电子 0.653406620026
控制工程 0.652179896832
电力系统 0.639267086983
智能化 0.635521113873
精密仪器 0.621204257011
农业机械 0.620398402214
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info">Wente Guo</span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info">http://chnwentao.com/2016/12/待整理/NLP-做一个自己的聊天机器人/</span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" target="_blank">CC BY-NC-SA 3.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/NLP/">NLP</a><a class="post-meta__tags" href="/tags/聊天机器人/">聊天机器人</a><a class="post-meta__tags" href="/tags/Python/">Python</a></div></article><nav id="pagination"><div class="prev-post pull-left"><a href="/2017/01/待整理/NLP-word2vec学习/"><i class="fa fa-chevron-left">  </i><span>基于 Gensim 的 Word2Vec 实践</span></a></div><div class="next-post pull-right"><a href="/2016/11/工具/工具-ATOM-安装及配置/"><span>ATOM使用及优化</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">©2015 - 2017 By Wente Guo</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.3"></script><script src="/js/fancybox.js?version=1.3"></script><script src="/js/sidebar.js?version=1.3"></script><script src="/js/copy.js?version=1.3"></script><script src="/js/fireworks.js?version=1.3"></script><script src="/js/transition.js?version=1.3"></script><script src="/js/scroll.js?version=1.3"></script><script src="/js/head.js?version=1.3"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body></html>