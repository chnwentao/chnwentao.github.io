<!DOCTYPE html><html lang=""><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>Spark基础概念——RDD | CS Learning of CHNwentao</title><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css?version=1.3"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?js?c4c99183a6a02c53d4760ae1995c3b38";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var GLOBAL = { 
  root: '/',
  algolia: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  localSearch: {"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}"},"path":"search.xml"}
} </script><link rel="icon" href="/favicon.ico"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#SparkContext类与SparkConf类"><span class="toc-number">1.</span> <span class="toc-text">SparkContext类与SparkConf类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#弹性分布式数据集-RDD"><span class="toc-number">2.</span> <span class="toc-text">弹性分布式数据集 RDD</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RDD的特点："><span class="toc-number">2.1.</span> <span class="toc-text">RDD的特点：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#内部表示"><span class="toc-number">2.2.</span> <span class="toc-text">内部表示</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RDD的持久化-存储与分区"><span class="toc-number">2.3.</span> <span class="toc-text">RDD的持久化-存储与分区</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RDD的生成"><span class="toc-number">2.4.</span> <span class="toc-text">RDD的生成</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RDD的操作"><span class="toc-number">2.5.</span> <span class="toc-text">RDD的操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#容错"><span class="toc-number">2.6.</span> <span class="toc-text">容错</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark与Hadoop的对比"><span class="toc-number"></span> <span class="toc-text">Spark与Hadoop的对比</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#背景知识"><span class="toc-number"></span> <span class="toc-text">背景知识</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#序列化"><span class="toc-number">1.</span> <span class="toc-text">序列化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#持久化"><span class="toc-number">2.</span> <span class="toc-text">持久化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-number"></span> <span class="toc-text">参考</span></a></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="http://7xiuu0.com1.z0.glb.clouddn.com/17-11-23/22222257.jpg"></div><div class="author-info__name text-center">Wente Guo</div><div class="author-info__description text-center">一个学习的博客网站，专注于计算机科学、机器学习、数据挖掘等的 技术分享、相关咨询及经验总结</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">149</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">196</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">21</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container" style="background-image: url(true);"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">CS Learning of CHNwentao</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span></div><div id="post-info"><div id="post-title">Spark基础概念——RDD</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2016-03-29</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"> </i><a class="post-meta__categories" href="/categories/Spark/">Spark</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">1,515</span><span class="post-meta__separator">|</span><span>Reading time: 5 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div id="post-content"><p>Spark基于map reduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的：spark是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。<a id="more"></a><br>这也是就我为什么要学习他的原因。</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><h3 id="SparkContext类与SparkConf类"><a href="#SparkContext类与SparkConf类" class="headerlink" title="SparkContext类与SparkConf类"></a>SparkContext类与SparkConf类</h3><p>任何Spark程序的编写都是从SparkContext(或用Java编写时的JavaSparkContext)开始 的。SparkContext的初始化需要一个SparkConf对象,后者包含了Spark集群配置的各种参数<br>(比如主节点的URL)。</p>
<h3 id="弹性分布式数据集-RDD"><a href="#弹性分布式数据集-RDD" class="headerlink" title="弹性分布式数据集 RDD"></a>弹性分布式数据集 RDD</h3><p>RDD是Spark最基本的抽象，是对分布式内存的抽象使用。它表示已被分区，不可变的并能够被并行操作的数据集合，不同的数据集格式对应不同的RDD实现。</p>
<h4 id="RDD的特点："><a href="#RDD的特点：" class="headerlink" title="RDD的特点："></a>RDD的特点：</h4><ul>
<li>它是在集群节点上的不可变的、已分区的集合对象。</li>
<li>通过并行转换的方式来创建如（map, filter, join, etc）。</li>
<li>失败自动重建。</li>
<li>可以控制存储级别（内存、磁盘等）来进行重用。</li>
<li>必须是可序列化的。</li>
<li>是静态类型的。</li>
</ul>
<p>RDD可以cache到内存中，每次对RDD数据集的操作之后的结果，都可以存放到内存中，下一个操作可以直接从内存中输入，省去了MapReduce大量的磁盘IO操作。这对于迭代运算比较常见的机器学习算法, 交互式的数据挖掘来说，效率提升很大！因为RDD的序列化特点，在内存不足时可自动降级为磁盘存储，把RDD存储于磁盘上，这时性能会有大的下降但不会差于现在的MapReduce。</p>
<p>由于RDD静态类型的的特性，Spark <strong>不适用</strong> 那种异步细粒度更新状态的应用（增量修改的应用模型），例如web服务的存储或者是增量的web爬虫和索引。</p>
<h4 id="内部表示"><a href="#内部表示" class="headerlink" title="内部表示"></a>内部表示</h4><ol>
<li>分区列表（数据块列表）</li>
<li>计算每个分片的函数（根据父RDD计算出此RDD）</li>
<li>对父RDD的依赖列表</li>
<li>对key-value RDD的Partitioner【可选】</li>
<li>每个数据分片的预定义地址列表(如HDFS上的数据块的地址)【可选</li>
</ol>
<h4 id="RDD的持久化-存储与分区"><a href="#RDD的持久化-存储与分区" class="headerlink" title="RDD的持久化-存储与分区"></a>RDD的持久化-存储与分区</h4><p>RDD根据useDisk、useMemory、deserialized、replication四个参数的组合提供了11种存储级别。<br>当前RDD默认是存储于内存，但当内存不足时，RDD会spill到disk。<br>RDD在需要进行分区把数据分布于集群中时会根据每条记录Key进行分区（如Hash 分区），以此保证两个数据集在Join时能高效。</p>
<h4 id="RDD的生成"><a href="#RDD的生成" class="headerlink" title="RDD的生成"></a>RDD的生成</h4><p>两种方式创建 RDDs：</p>
<ul>
<li>在你的驱动程序中并行化一个已经存在的集合；</li>
<li>是引用一个外部存储系统的数据集，例如共享的文件系统，HDFS，HBase或其他 Hadoop 数据格式的数据源。</li>
</ul>
<h4 id="RDD的操作"><a href="#RDD的操作" class="headerlink" title="RDD的操作"></a>RDD的操作</h4><p>对于RDD可以有两种计算方式：转换（返回值还是一个RDD）与操作（返回值不是一个RDD）。<br>注意：Transformations操作是Lazy的，也就是说从一个RDD转换生成另一个RDD的操作不是马上执行，Spark在遇到Transformations操作时只会记录需要这样的操作，并不会去执行，需要等到有Actions操作的时候才会真正启动计算过程进行计算。</p>
<h4 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h4><h2 id="Spark与Hadoop的对比"><a href="#Spark与Hadoop的对比" class="headerlink" title="Spark与Hadoop的对比"></a>Spark与Hadoop的对比</h2><ol>
<li>Spark的中间数据放到内存中，对于迭代运算效率更高。<ul>
<li>Spark更适合于迭代运算比较多的ML和DM运算。</li>
<li>hadoop更适用于数据量小但是计算密集度较大的场合。</li>
</ul>
</li>
<li>可用性。<ul>
<li>Spark通过提供丰富的Scala, Java，Python API及交互式Shell来提高可用性。</li>
</ul>
</li>
<li>容错性。<ul>
<li>在分布式数据集计算时通过checkpoint来实现容错，而checkpoint有两种方式，一个是- checkpoint data，一个是logging the updates。用户可以控制采用哪种方式来实现容错。</li>
</ul>
</li>
</ol>
<h2 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h2><h3 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h3><p>数据序列化就是将对象或者数据结构转化成特定的格式，使其可在网络中传输，或者可存储在内存或者文件中。反序列化则是相反的操作，将对象从序列化数据中还原出来。而对象序列化后的数据格式可以是二进制，可以是XML，也可以是JSON等任何格式。对象/数据序列化的重点在于数据的交换和传输，例如在远程调用技术(如EJB,XML-RPC, Web Service)，或者在GUI控件开发(JavaBean)等等。<br>Java 提供了一种对象序列化的机制，该机制中，一个对象可以被表示为一个字节序列，该字节序列包括该对象的数据、有关对象的类型的信息和存储在对象中数据的类型。<br>将序列化对象写入文件之后，可以从文件中读取出来，并且对它进行反序列化，也就是说，对象的类型信息、对象的数据，还有对象中的数据类型可以用来在内存中新建对象。</p>
<h3 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h3><p>对象持久化就是将对象存储在可持久保存的存储介质上，例如主流的关系数据库中。在实际应用中，需要将业务数据以对象的方式保存在数据库中，就需要应用到相应的对象持久化框架，如现在广为认知的Hibernate。而如果查阅对象持久化的历史，你会发现早在1970年就已经开始有称之为面向对象数据库OODBMS。通常这些面向对象的数据库和特定的一种语言绑定。对象持久化的重点在于如何将业务数据对象存储在持久化介质上，并同时提供查询修改的手段。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://tech.uc.cn/?p=2116" target="_blank" rel="noopener">Spark：一个高效的分布式计算系统</a></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info">Wente Guo</span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info">http://chnwentao.com/2016/03/大数据工具/Spark-总结-基础概念理解/</span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" target="_blank">CC BY-NC-SA 3.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/saprk/">saprk</a><a class="post-meta__tags" href="/tags/RDD/">RDD</a><a class="post-meta__tags" href="/tags/SparkConf/">SparkConf</a></div></article><nav id="pagination"><div class="prev-post pull-left"><a href="/2016/03/待整理/Python3-笔记-IO编程/"><i class="fa fa-chevron-left">  </i><span>python3-IO编程</span></a></div><div class="next-post pull-right"><a href="/2016/03/随笔/生活-数据相关职位调查/"><span>数据相关职位情况统计调查</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">©2015 - 2017 By Wente Guo</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a><span class="footer-separator">|</span><span>Hosted by </span><a href="https://pages.coding.me"><span>Coding Pages</span></a></div><div class="busuanzi"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.3"></script><script src="/js/fancybox.js?version=1.3"></script><script src="/js/sidebar.js?version=1.3"></script><script src="/js/copy.js?version=1.3"></script><script src="/js/fireworks.js?version=1.3"></script><script src="/js/transition.js?version=1.3"></script><script src="/js/scroll.js?version=1.3"></script><script src="/js/head.js?version=1.3"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body></html>